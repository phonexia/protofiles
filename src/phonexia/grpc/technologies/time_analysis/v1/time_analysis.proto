// Copyright 2025 Phonexia s.r.o.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Phonexia Time Analysis gRPC API.
syntax = "proto3";

package phonexia.grpc.technologies.time_analysis.v1;

import "phonexia/grpc/common/core.proto";
import "google/protobuf/duration.proto";

// Service implementing Time Analysis.
service TimeAnalysis {
  // Performs synchronous Time Analysis.
  // The analysis starts after the whole audio has been received.
  rpc Analyze(stream AnalyzeRequest) returns (stream AnalyzeResponse);
}

// The top-level message sent by the client for the <code>Analyze</code>
// method.
message AnalyzeRequest {
  // Audio data for which Time Analysis should be performed.
  // Audio can be either mono or stereo. In case of mono, only the ChannelAnalysis
  // message is returned. At least 900 milliseconds of audio is required, otherwise
  // the result will not contain any analyses.
  phonexia.grpc.common.Audio audio = 1;
}

// Time Analysis of how an individual channel reacts to the other channel.
message ReactionAnalysis {
  // Index of the channel whose reactions are analyzed.
  int32 reacting_channel = 1;
  // Number of reactions of this channel to the other channel. A "reaction" is defined
  // as the act when the speaker in the reacting channel starts speaking AFTER the
  // speaker in the other channel has stopped speaking.
  uint64 reactions_count = 2;
  // Average time that elapsed between the speaker in the other channel stopped speaking
  // and the speaker in the reacting channel started speaking.
  // When no reaction to the other channel was detected, this field is set to 0.
  google.protobuf.Duration average_reaction_time = 3;
  // Position of this channel's fastest reaction (shortest reaction time).
  // When no reaction to the other channel was detected, this field is set to 0.
  phonexia.grpc.common.TimeRange fastest_reaction_position = 4;
  // Position of this channel's slowest reaction (longest reaction time).
  // When no reaction to the other channel was detected, this field is set to 0.
  phonexia.grpc.common.TimeRange slowest_reaction_position = 5;
  // List of positions of this channel's crosstalks. A "crosstalk" is defined as the act
  // when the speaker in the reacting channel starts speaking WHILE the speaker in the
  // other channel is still speaking. The crosstalk lasts as long as both speakers are
  // speaking.
  repeated phonexia.grpc.common.TimeRange crosstalks = 6;
}

// Time Analysis for an individual channel.
message ChannelAnalysis {
  // Index of the channel.
  int32 channel_number = 1;
  // Length of speech in this channel.
  google.protobuf.Duration speech_length = 2;
  // Speech rate as the number of phonemes per second.
  optional float speech_rate = 3;
  // Length of audio in this channel.
  google.protobuf.Duration total_length = 4;
}

// The collection of all Time Analysis result types.
message AnalyzeResult {
  // List of Time Analyses for individual channels.
  repeated ChannelAnalysis channel_analyses = 1;
  // List of Time Analyses for channel combinations.
  repeated ReactionAnalysis reaction_analyses = 2;
}

// The top-level message returned to the client by the <code>Analyze</code>
// method.
message AnalyzeResponse {
  // Time Analysis result.
  AnalyzeResult result = 1;

  // Total length of the processed audio.
  // Set only if this is the last response in the stream.
  google.protobuf.Duration processed_audio_length = 2;
}