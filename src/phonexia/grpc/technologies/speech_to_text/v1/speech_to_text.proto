// Copyright 2025 Phonexia s.r.o.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Phonexia 6 generation Speech To Text gRPC API.
syntax = "proto3";

package phonexia.grpc.technologies.speech_to_text.v1;

import "phonexia/grpc/common/core.proto";
import "google/protobuf/duration.proto";

// Service implementing speech-to-text transcription.
service SpeechToText {
  // Performs synchronous speech-to-text transcription.
  // The transcription starts after the whole audio has been received.
  rpc Transcribe (stream TranscribeRequest) returns (stream TranscribeResponse);

  // <code>ListAllowedSymbols</code> returns lists of allowed graphemes and phonemes.
  rpc ListAllowedSymbols (ListAllowedSymbolsRequest) returns (ListAllowedSymbolsResponse);
}

// Enum defining the types of results that can be returned in TranscribeResult.
enum ResultType {
  // Default one-best transcription result.
  RESULT_TYPE_ONE_BEST = 0;

  // N-best alternative transcription results.
  RESULT_TYPE_N_BEST = 1;

  // Confusion network with word alternatives.
  RESULT_TYPE_CONFUSION_NETWORK = 2;
}

// The top-level message sent by the client for the <code>Transcribe</code>
// method.
message TranscribeRequest {
  // The audio data to process. There is no minimum audio length limit.
  phonexia.grpc.common.Audio audio = 1;

  // Speech to text transcription configuration.
  optional TranscribeConfig config = 2;
}

message TranscribeConfig {
  // Phrases that are preferred in transcription over other variants. Phrase consists of words spelled using graphemes
  // separated by space. Graphemes that are not valid for transcription language might be used. However, the word must
  // be added to <code>additional_words</code> and contains at least one pronunciation.
  // Use <code>ListAllowedSymbols</code> to get allowed graphemes.
  // All words from preferred phrases are automatically added to the model's dictionary and included in
  // <code>TranscribeResponse.result.additional_words</code>.
  repeated string preferred_phrases = 1;

  // Words that are added to the default transcription dictionary.
  repeated RequestedAdditionalWord additional_words = 2;

  // Types of results to return in the response.
  // If not specified, <code>RESULT_TYPE_ONE_BEST</code> will be used.
  repeated ResultType result_types = 3;
}

message RequestedAdditionalWord {
  // Word spelled using graphemes. Graphemes that are not valid for transcription
  // language might be used. However, in such case, at least one pronunciation must
  // be provided. Multiple words can be separated by word separator.
  // Use <code>ListAllowedSymbols</code> to get allowed graphemes and word separator.
  string spelling = 1;

  // Pronunciations specified using transcription language's valid phonemes.
  // Individual phonemes must be separated by space. If no pronunciation is provided,
  // at least one is generated by the language model. Use <code>ListAllowedSymbols</code> to get allowed phonemes.
  // At least 3 phonemes are required.
  repeated string pronunciations = 2;
}

enum ItemType {
  // <code>ITEM_TYPE_WORD</code> indicates a word.
  // The <code>text</code> field of the item contains the word.
  ITEM_TYPE_WORD = 0;

  // <code>ITEM_TYPE_SILENCE</code> indicates a silence in the recording.
  // The <code>text</code> field of the item contains "&lt;silence/&gt;".
  ITEM_TYPE_SILENCE = 1;

  // <code>ITEM_TYPE_SEGMENT_START</code> indicates the start of a segment.
  // A segment is a part of the recording that contains speech,
  // as determined by the Voice Activity Detector (VAD).
  // The <code>text</code> field of the item contains "&lt;segment&gt;".
  ITEM_TYPE_SEGMENT_START = 2;

  // <code>ITEM_TYPE_SEGMENT_END</code> indicates the end of a segment.
  // A segment is a part of the recording that contains speech,
  // as determined by the Voice Activity Detector (VAD).
  // The <code>text</code> field of the item contains "&lt;/segment&gt;".
  ITEM_TYPE_SEGMENT_END = 3;

  // <code>ITEM_TYPE_NULL</code> represents an empty alternative in a confusion network.
  // The <code>text</code> field of the item contains "<null/>".
  ITEM_TYPE_NULL = 4;
}

// Individual word with timestamps.
message Word {
  // Text of the word.
  string text = 1;

  // Start time of the word.
  google.protobuf.Duration start_time = 2;

  // End time of the word.
  google.protobuf.Duration end_time = 3;

  // Type of the word. It might be <code>ITEM_TYPE_WORD</code> or <code>ITEM_TYPE_SILENCE</code>.
  // <code>ITEM_TYPE_SEGMENT_START</code>, <code>ITEM_TYPE_SEGMENT_END</code> and <code>ITEM_TYPE_NULL</code> are not allowed here.
  // When type is <code>ITEM_TYPE_SILENCE</code>, text contains "&lt;silence/&gt;", otherwise text contains the word.
  // Words of <code>ITEM_TYPE_SILENCE</code> are only included in OneBest if their duration is greater than 180ms.
  ItemType type = 4;
}

// Segment of the one-best output.
message OneBestSegment {
  // Text content of the whole segment.
  string text = 1;

  // Start time of the segment.
  google.protobuf.Duration start_time = 2;

  // End time of the segment.
  google.protobuf.Duration end_time = 3;

  // Detailed word-level segmentation of the segment.
  repeated Word words = 4;
}

// The one-best output from Speech to Text.
message OneBest {
  // List of transcription segments
  repeated OneBestSegment segments = 1;
 }

// Alternative of a segment.
message NBestSegmentAlternative {
  // The text of the segment.
  string text = 1;

  // Confidence of the segment.
  float confidence = 2;

  // Start time of the segment.
  google.protobuf.Duration start_time = 3;

  // End time of the segment.
  google.protobuf.Duration end_time = 4;
}

message NBestSegment {
  // The alternatives of the segment.
  repeated NBestSegmentAlternative segment_alternatives = 1;
}

// The n-best output from Speech to Text.
message NBest {
  // List of segments.
  repeated NBestSegment segments = 1;
}

message ConfusionNetworkWordAlternative {
  // Text of the word.
  string text = 1;

  // Start time of the segment.
  google.protobuf.Duration start_time = 2;

  // End time of the segment.
  google.protobuf.Duration end_time = 3;

  // Confidence of the word.
  float confidence = 4;

  // Type of the word. When type is <code>ITEM_TYPE_WORD</code> then text contains the word. In other cases text contains:
  // <code>ITEM_TYPE_SILENCE</code> - "&lt;silence/&gt;"
  // <code>ITEM_TYPE_SEGMENT_START</code> - "&lt;segment&gt;"
  // <code>ITEM_TYPE_SEGMENT_END</code> - "&lt;/segment&gt;"
  // <code>ITEM_TYPE_NULL</code> - "&lt;null/&gt;"
  ItemType type = 5;
}

message ConfusionNetworkWord {
  // Words in the time slot represent different
  // variants of the word in the given time moment.
  repeated ConfusionNetworkWordAlternative word_alternatives = 1;
}

message ConfusionNetwork {
  // The confusion network.
  repeated ConfusionNetworkWord words = 1;
}

// Result of the Speech to Text.
message TranscribeResult {
  // The one-best output from Speech to Text.
  optional OneBest one_best = 1;

  // The n-best output from Speech to Text.
  optional NBest n_best = 2;

  // The confusion network output from Speech to Text.
  optional ConfusionNetwork confusion_network = 3;

  // Words that were used to extend model's dictionary during transcription.
  // This list is the result of their processing. If they were originally part
  // of a preferred phrase, they are explicitly listed here. Furthermore, the model
  // might have generated pronunciation for unknown words that were missing one.
  // Lastly, if user provided a word that's already present in the model
  // dictionary, all the known pronunciations were added to it.
  repeated ResultingAdditionalWord additional_words = 4;

  // Language of the transcript.
  string language = 5;
}

message ResultingAdditionalWord {
  // Word spelling as originally provided by the user.
  string spelling = 1;

  // Word pronunciation after being processed by the language model.
  repeated ResultingPronunciation pronunciations = 2;
}

message ResultingPronunciation {
  // Pronunciation specified using transcription language's valid phonemes.
  string pronunciation = 1;

  // Indication of whether the pronunciation is previously unknown to the model.
  bool out_of_vocabulary = 2;
}

// TranscribeResponse is the top-level response message returned by the <code>Transcribe</code> method.
// It encapsulates segments containing the transcription results.
message TranscribeResponse {
  // Transcription result for the processed audio.
  TranscribeResult result = 1;

  // Total duration of the processed audio.
  google.protobuf.Duration processed_audio_length = 2;
}

// Request message for retrieving the set of allowed graphemes and phonemes.
message ListAllowedSymbolsRequest {}

// Response message containing the allowed graphemes and phonemes.
message ListAllowedSymbolsResponse {

  // The list of allowed graphemes. Graphemes are characters used in
  // <code>TranscribeConfig.preferred_phrases</code> and
  // <code>RequestedAdditionalWord.spelling</code>.
  repeated string graphemes = 1;

  // List of allowed phonemes.
  // Phonemes are symbols used in the <code>RequestedAdditionalWord.pronunciations</code> field.
  // Each phoneme is represented as a space-separated string and may consist of multiple characters.
  repeated string phonemes = 2;

  // Word separator used in <code>TranscribeConfig.additional_words.spelling</code>
  string word_separator = 3;
}